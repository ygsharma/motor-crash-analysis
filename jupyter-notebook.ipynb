{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1b457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3714faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType, DecimalType\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "import folium\n",
    "from folium.plugins import HeatMapWithTime,HeatMap\n",
    "from folium import plugins\n",
    "\n",
    "from ipywidgets import interact, widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ac3c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from itertools import chain\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import chart_studio.dashboard_objs as dashboard\n",
    "from dash import Dash, html, dash_table, dcc, Input, Output\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a70a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"Motor Crash Analysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076bcd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = spark.read.csv(\"Motor_Vehicle_Collisions_-_Crashes_20231026.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d1615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows where there's no street name\n",
    "df = df.na.drop(how='all', subset=['ON STREET NAME', 'CROSS STREET NAME', 'OFF STREET NAME'])\n",
    "\n",
    "# Important features that cannot be Null for our analysis\n",
    "df = df.na.drop(subset=['CRASH DATE', 'CRASH TIME', 'BOROUGH', 'ZIP CODE', 'LOCATION'])\n",
    "\n",
    "# Dropping rows where there are no contributing factors mentioned\n",
    "df = df.na.drop(how='all', subset=['CONTRIBUTING FACTOR VEHICLE 1', 'CONTRIBUTING FACTOR VEHICLE 2', \n",
    "                                   'CONTRIBUTING FACTOR VEHICLE 3', 'CONTRIBUTING FACTOR VEHICLE 4',\n",
    "                                   'CONTRIBUTING FACTOR VEHICLE 5'])\n",
    "\n",
    "# Dropping rows where there are vehicle type mentioned\n",
    "df = df.na.drop(how='all', subset=['VEHICLE TYPE CODE 1', 'VEHICLE TYPE CODE 2', \n",
    "                                   'VEHICLE TYPE CODE 3', 'VEHICLE TYPE CODE 4',\n",
    "                                   'VEHICLE TYPE CODE 5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1400323",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = df.alias('df_orig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2199846d",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176ca560",
   "metadata": {},
   "source": [
    "## Month wise plot of number of accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a1615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'CRASH DATE' column is in datetime format\n",
    "df = df.withColumn('CRASH DATE', F.to_timestamp(F.regexp_replace('CRASH DATE', '/', '-'), \"MM-dd-yyyy\"))\n",
    "\n",
    "# Extract the month from the date\n",
    "df = df.withColumn('Month', F.month('CRASH DATE'))\n",
    "\n",
    "# Count the number of accidents per month\n",
    "accidents_per_month = df.groupBy('Month').count().orderBy('Month')\n",
    "\n",
    "# Collect the data to a Pandas DataFrame for plotting\n",
    "accidents_per_month_pd = accidents_per_month.toPandas().set_index('Month')\n",
    "\n",
    "# Plotting\n",
    "fig1 = px.bar(accidents_per_month_pd, x=accidents_per_month_pd.index, y=accidents_per_month_pd.columns[0])\n",
    "\n",
    "# Update the layout\n",
    "fig1.update_layout(\n",
    "    xaxis_title='Month',\n",
    "    yaxis_title='Number of Accidents',\n",
    "    xaxis=dict(tickmode='array', tickvals=list(range(12)), ticktext=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                                                                     'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']),\n",
    "    plot_bgcolor = \"#31302F\", \n",
    "    paper_bgcolor = \"#31302F\",\n",
    "    font=dict(family=\"Open Sans\", color='#9467bd')\n",
    ")\n",
    "\n",
    "fig1.update_traces(marker_color = '#e377c2')\n",
    "\n",
    "# Show the plot\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bbc940",
   "metadata": {},
   "source": [
    "## How frequent the Accident happened by Day of Week and Hour of Day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aee069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract day of the week (1=Sunday, 7=Saturday) and hour of the day\n",
    "df = df.withColumn('day_of_week', F.dayofweek(F.col('CRASH DATE')))\n",
    "df = df.withColumn('hour_of_day', F.hour(F.col('CRASH TIME')))\n",
    "\n",
    "# Group and count accidents by day of the week and hour of day\n",
    "accidents_count = df.groupBy('day_of_week', 'hour_of_day').count()\n",
    "\n",
    "# Pivot the data for plotting\n",
    "pivot_df = accidents_count.groupBy('day_of_week').pivot('hour_of_day').sum('count')\n",
    "pivot_df = pivot_df.where(pivot_df['day_of_week'] > 0)\n",
    "pivot_df = pivot_df.drop('null')\n",
    "\n",
    "# Fill NaN values with 0\n",
    "pivot_df = pivot_df.na.fill(0)\n",
    "\n",
    "# Convert to Pandas DataFrame for plotting\n",
    "pivot_table_pd = pivot_df.toPandas()\n",
    "pivot_table_pd.set_index('day_of_week', inplace=True)\n",
    "pivot_table_pd.sort_index(inplace=True)\n",
    "\n",
    "# Create a heatmap with Plotly\n",
    "fig2 = go.Figure(data=go.Heatmap(\n",
    "    z=pivot_table_pd.values,\n",
    "    x=pivot_table_pd.columns,\n",
    "    y=pivot_table_pd.index,\n",
    "    colorscale='matter'\n",
    "))\n",
    "\n",
    "# Adding text annotations to each cell\n",
    "for yd, day in enumerate(pivot_table_pd.index):\n",
    "    for xd, hour in enumerate(pivot_table_pd.columns):\n",
    "        fig2.add_annotation(\n",
    "            x=hour,\n",
    "            y=day,\n",
    "            text=str(pivot_table_pd.loc[day, hour]),\n",
    "            showarrow=False,\n",
    "            font=dict(color=\"black\")\n",
    "        )\n",
    "\n",
    "# Update the layout\n",
    "fig2.update_layout(\n",
    "    xaxis_title='Hour of Day',\n",
    "    yaxis_title='Day of Week',\n",
    "    yaxis=dict(\n",
    "        tickmode='array',\n",
    "        tickvals=[1, 2, 3, 4, 5, 6, 7],\n",
    "        ticktext=['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "    ),\n",
    "    plot_bgcolor = \"#31302F\", \n",
    "    paper_bgcolor = \"#31302F\",\n",
    "    font=dict(family=\"Open Sans\", color='#9467bd')\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40b0b66",
   "metadata": {},
   "source": [
    "## Number of Injuries and Killed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6d0d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: Aggregating Data by Date\n",
    "daily_data = df.groupBy('CRASH DATE').agg(\n",
    "    F.sum('NUMBER OF PERSONS KILLED').alias('NUMBER OF PERSONS KILLED'),\n",
    "    F.sum('NUMBER OF PEDESTRIANS KILLED').alias('NUMBER OF PEDESTRIANS KILLED'),\n",
    "    F.sum('NUMBER OF CYCLIST KILLED').alias('NUMBER OF CYCLIST KILLED'),\n",
    "    F.sum('NUMBER OF MOTORIST KILLED').alias('NUMBER OF MOTORIST KILLED')\n",
    ").sort('CRASH DATE')\n",
    "\n",
    "# Use cumsum() if you want to show cumulative data\n",
    "window_spec = Window.orderBy('CRASH DATE')\n",
    "for col in daily_data.columns:\n",
    "    if col != 'CRASH DATE':\n",
    "        daily_data = daily_data.withColumn(col, F.sum(daily_data[col]).over(window_spec))\n",
    "\n",
    "# Convert to Pandas DataFrame for plotting (assuming the dataset is small enough)\n",
    "pdf = daily_data.toPandas()\n",
    "\n",
    "# Plotting a stacked area chart\n",
    "fig3 = go.Figure()\n",
    "\n",
    "# Add traces for each category\n",
    "fig3.add_trace(go.Scatter(\n",
    "    x=pdf['CRASH DATE'], y=pdf['NUMBER OF PERSONS KILLED'],\n",
    "    mode='lines', name='Persons Killed', stackgroup='one'\n",
    "))\n",
    "fig3.add_trace(go.Scatter(\n",
    "    x=pdf['CRASH DATE'], y=pdf['NUMBER OF PEDESTRIANS KILLED'],\n",
    "    mode='lines', name='Pedestrians Killed', stackgroup='one'\n",
    "))\n",
    "fig3.add_trace(go.Scatter(\n",
    "    x=pdf['CRASH DATE'], y=pdf['NUMBER OF CYCLIST KILLED'],\n",
    "    mode='lines', name='Cyclists Killed', stackgroup='one'\n",
    "))\n",
    "fig3.add_trace(go.Scatter(\n",
    "    x=pdf['CRASH DATE'], y=pdf['NUMBER OF MOTORIST KILLED'],\n",
    "    mode='lines', name='Motorists Killed', stackgroup='one'\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig3.update_layout(\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Cumulative Number',\n",
    "    legend_title='Category',\n",
    "    hovermode='x',\n",
    "    plot_bgcolor = \"#31302F\", \n",
    "    paper_bgcolor = \"#31302F\",\n",
    "    font=dict(family=\"Open Sans\", color='#9467bd')\n",
    ")\n",
    "\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a2b5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the 'number_of_injured' column based on conditions\n",
    "killed_df = df.withColumn('NUMBER OF PERSONS KILLED', \n",
    "                               F.when(F.col('NUMBER OF PERSONS KILLED') > 5, 'More than 5')\n",
    "                               .when(F.col('NUMBER OF PERSONS KILLED') > 2, '3-5')\n",
    "                               .otherwise(F.col('NUMBER OF PERSONS KILLED'))\n",
    "                              )\n",
    "\n",
    "# Aggregate data for the pie chart\n",
    "killed_df = killed_df.groupBy('NUMBER OF PERSONS KILLED').count()\n",
    "\n",
    "# Note: Plotly cannot directly visualize Spark DataFrames. \n",
    "# You would need to convert it back to a Pandas DataFrame for visualization.\n",
    "pandas_df = killed_df.toPandas()\n",
    "pandas_df = pandas_df.dropna(subset=['NUMBER OF PERSONS KILLED'])\n",
    "pandas_df = pandas_df[pandas_df['NUMBER OF PERSONS KILLED'] != '0']\n",
    "sorted_df = pandas_df.sort_values(by='NUMBER OF PERSONS KILLED', ascending=True)\n",
    "\n",
    "# Now you can use Plotly to visualize the data\n",
    "fig4 = px.pie(sorted_df, values='count', names='NUMBER OF PERSONS KILLED',\n",
    "             color_discrete_sequence=px.colors.diverging.PRGn)\n",
    "\n",
    "fig4.update_layout(\n",
    "    plot_bgcolor = \"#31302F\", \n",
    "    paper_bgcolor = \"#31302F\",\n",
    "    font=dict(family=\"Open Sans\", color='#9467bd')\n",
    ")\n",
    "\n",
    "fig4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e17a13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Part 1: Aggregating Data by Date\n",
    "daily_data = df.groupBy('CRASH DATE').agg(\n",
    "    F.sum('NUMBER OF PERSONS INJURED').alias('NUMBER OF PERSONS INJURED'),\n",
    "    F.sum('NUMBER OF PEDESTRIANS INJURED').alias('NUMBER OF PEDESTRIANS INJURED'),\n",
    "    F.sum('NUMBER OF CYCLIST INJURED').alias('NUMBER OF CYCLIST INJURED'),\n",
    "    F.sum('NUMBER OF MOTORIST INJURED').alias('NUMBER OF MOTORIST INJURED')\n",
    ").sort('CRASH DATE')\n",
    "\n",
    "# Use cumsum() if you want to show cumulative data\n",
    "window_spec = Window.orderBy('CRASH DATE')\n",
    "for col in daily_data.columns:\n",
    "    if col != 'CRASH DATE':\n",
    "        daily_data = daily_data.withColumn(col, F.sum(daily_data[col]).over(window_spec))\n",
    "\n",
    "# Convert to Pandas DataFrame for plotting (assuming the dataset is small enough)\n",
    "pdf = daily_data.toPandas()\n",
    "\n",
    "# Plotting a stacked area chart with Plotly\n",
    "fig5 = go.Figure()\n",
    "\n",
    "# Add traces for each category\n",
    "fig5.add_trace(go.Scatter(\n",
    "    x=pdf['CRASH DATE'], y=pdf['NUMBER OF PERSONS INJURED'],\n",
    "    mode='lines', name='Persons Injured', stackgroup='one'\n",
    "))\n",
    "fig5.add_trace(go.Scatter(\n",
    "    x=pdf['CRASH DATE'], y=pdf['NUMBER OF PEDESTRIANS INJURED'],\n",
    "    mode='lines', name='Pedestrians Injured', stackgroup='one'\n",
    "))\n",
    "fig5.add_trace(go.Scatter(\n",
    "    x=pdf['CRASH DATE'], y=pdf['NUMBER OF CYCLIST INJURED'],\n",
    "    mode='lines', name='Cyclists Injured', stackgroup='one'\n",
    "))\n",
    "fig5.add_trace(go.Scatter(\n",
    "    x=pdf['CRASH DATE'], y=pdf['NUMBER OF MOTORIST INJURED'],\n",
    "    mode='lines', name='Motorists Injured', stackgroup='one'\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig5.update_layout(\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Cumulative Number',\n",
    "    legend_title='Category',\n",
    "    hovermode='x unified',\n",
    "    plot_bgcolor = \"#31302F\", \n",
    "    paper_bgcolor = \"#31302F\",\n",
    "    font=dict(family=\"Open Sans\", color='#9467bd')\n",
    ")\n",
    "\n",
    "fig5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982465aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the 'number_of_injured' column based on conditions\n",
    "injured_df = df.withColumn('NUMBER OF PERSONS INJURED', \n",
    "                               F.when(F.col('NUMBER OF PERSONS INJURED') > 5, 'More than 5')\n",
    "                               .when(F.col('NUMBER OF PERSONS INJURED') > 2, '3-5')\n",
    "                               .otherwise(F.col('NUMBER OF PERSONS INJURED'))\n",
    "                              )\n",
    "\n",
    "# Aggregate data for the pie chart\n",
    "injured_df = injured_df.groupBy('NUMBER OF PERSONS INJURED').count()\n",
    "\n",
    "# Note: Plotly cannot directly visualize Spark DataFrames. \n",
    "# You would need to convert it back to a Pandas DataFrame for visualization.\n",
    "pandas_df = injured_df.toPandas()\n",
    "pandas_df = pandas_df.dropna(subset=['NUMBER OF PERSONS INJURED'])\n",
    "sorted_df = pandas_df.sort_values(by='NUMBER OF PERSONS INJURED', ascending=True)\n",
    "\n",
    "# Now you can use Plotly to visualize the data\n",
    "fig6 = px.pie(sorted_df, values='count', names='NUMBER OF PERSONS INJURED',\n",
    "             color_discrete_sequence=px.colors.diverging.PRGn)\n",
    "\n",
    "fig6.update_layout(\n",
    "    plot_bgcolor = \"#31302F\", \n",
    "    paper_bgcolor = \"#31302F\",\n",
    "    font=dict(family=\"Open Sans\", color='#9467bd')\n",
    ")\n",
    "\n",
    "fig6.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d755dbb9",
   "metadata": {},
   "source": [
    "## Top 10 streets where accidents reported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a230d4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your PySpark DataFrame and it's already loaded\n",
    "# Count the number of accidents per street\n",
    "street_counts = df.groupBy(\"ON STREET NAME\").count().orderBy(F.col(\"count\").desc())\n",
    "\n",
    "top_streets_excluding_first = spark.createDataFrame(street_counts.tail(street_counts.count()-1), street_counts.schema)\n",
    "top_streets_for_plotting = spark.createDataFrame(top_streets_excluding_first.head(10), top_streets_excluding_first.schema)\n",
    "\n",
    "# Show the results\n",
    "top_streets_for_plotting.show()\n",
    "\n",
    "# For plotting, collect the data to the driver (local machine)\n",
    "top_streets_data = top_streets_for_plotting.toPandas()\n",
    "\n",
    "# For plotting, collect the data to the driver (local machine)\n",
    "fig7 = px.bar(top_streets_data, x='ON STREET NAME', y='count')\n",
    "\n",
    "# Update layout for the axes and plot\n",
    "fig7.update_layout(\n",
    "    xaxis_title='Street Name',\n",
    "    yaxis_title='Number of Accidents',\n",
    "    xaxis={'categoryorder':'total descending'},  # This ensures that bars are sorted by count\n",
    "    plot_bgcolor = \"#000000\", \n",
    "    paper_bgcolor = \"#000000\",\n",
    "    font=dict(family=\"Open Sans\", color='#9467bd')\n",
    ")\n",
    "\n",
    "fig7.update_traces(marker_color = '#e377c2')\n",
    "# Show the figure\n",
    "fig7.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb88c511",
   "metadata": {},
   "source": [
    "## Top 10 contribution factors for accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20416ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame is loaded\n",
    "factors_columns = ['CONTRIBUTING FACTOR VEHICLE 1']\n",
    "\n",
    "# Filter out null values\n",
    "non_null_factors = df.filter(df[factors_columns[0]].isNotNull())\n",
    "\n",
    "# Count the occurrences of each factor and get the top 11\n",
    "top_11_factors = non_null_factors.groupBy(factors_columns[0]) \\\n",
    "                                 .count() \\\n",
    "                                 .orderBy(F.col(\"count\").desc()) \\\n",
    "                                 .limit(11)\n",
    "\n",
    "top_10_factors = spark.createDataFrame(top_11_factors.tail(top_11_factors.count()-1), top_11_factors.schema)\n",
    "\n",
    "# Show the top 10 contributing factors\n",
    "top_10_factors.show()\n",
    "\n",
    "# Collect data for plotting\n",
    "top_10_data = top_10_factors.toPandas()\n",
    "\n",
    "# Plotting\n",
    "# Create a bar chart with Plotly Express\n",
    "fig8 = px.bar(top_10_data, x=factors_columns[0], y='count')\n",
    "\n",
    "# Update the layout\n",
    "fig8.update_layout(\n",
    "    title='Top 10 contribution factors for accidents',\n",
    "    xaxis_title='Contributing Factor',\n",
    "    yaxis_title='Number of Accidents',\n",
    "    plot_bgcolor = \"#000000\", \n",
    "    paper_bgcolor = \"#000000\",\n",
    "    font=dict(family=\"Open Sans\", color='#9467bd')\n",
    ")\n",
    "\n",
    "fig8.update_traces(marker_color = '#e377c2')\n",
    "# Show the plot\n",
    "fig8.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e7f2f4",
   "metadata": {},
   "source": [
    "## Which vehicle type was involved in most crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf5eb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_code_combined = df.select(F.col('VEHICLE TYPE CODE 1').alias('vehicle_codes')).\\\n",
    "                              union(df.select(F.col('VEHICLE TYPE CODE 2').alias('vehicle_codes'))).\\\n",
    "                              groupby('vehicle_codes').count().sort(F.col('count'), ascending=False)\n",
    "\n",
    "vehicle_code_data = vehicle_code_combined.collect()\n",
    "vehicle_code_data = [[ind['vehicle_codes'], ind['count']] for ind in vehicle_code_data]\n",
    "\n",
    "# Removing empty values\n",
    "empty_value_list = [None, 'None', 'UNKNOWN', 'OTHER']\n",
    "vehicle_code_data_filtered = [sublist for sublist in vehicle_code_data if sublist[0] not in empty_value_list]\n",
    "\n",
    "# Merging values that are the same but written differently\n",
    "# To later delete duplciates\n",
    "\n",
    "\n",
    "# Function to merge values\n",
    "def vehicle_code_merge(vehicle, data):\n",
    "    vehicle_ele = [vehicle, 0]\n",
    "    # To store indices of duplicates\n",
    "    del_inds = []\n",
    "    for ind, sub_l in enumerate(data):\n",
    "        if re.search(vehicle, sub_l[0], re.IGNORECASE):\n",
    "            vehicle_ele[1] += sub_l[1]\n",
    "            del_inds.append(ind)\n",
    "    \n",
    "    data.append(vehicle_ele)\n",
    "    data = [i for j, i in enumerate(data) if j not in set(del_inds)]\n",
    "    \n",
    "    return data\n",
    "\n",
    "vehicle_code_data_filtered = vehicle_code_merge('Station Wagon', vehicle_code_data_filtered)\n",
    "vehicle_code_data_filtered = vehicle_code_merge('Sedan', vehicle_code_data_filtered)\n",
    "vehicle_code_data_filtered = vehicle_code_merge('Taxi', vehicle_code_data_filtered)\n",
    "vehicle_code_data_filtered = vehicle_code_merge('Bus', vehicle_code_data_filtered)\n",
    "vehicle_code_data_filtered = vehicle_code_merge('Truck', vehicle_code_data_filtered)\n",
    "vehicle_code_data_filtered = vehicle_code_merge('Van', vehicle_code_data_filtered)\n",
    "\n",
    "vehicle_code_data_filtered = sorted(vehicle_code_data_filtered, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Prepare your data\n",
    "vehicle_types = [str(i[0]) for i in vehicle_code_data_filtered[:5]]\n",
    "counts = [i[1] for i in vehicle_code_data_filtered[:5]]\n",
    "\n",
    "# Create a bar chart with Plotly Express\n",
    "fig9 = px.bar(x=vehicle_types, y=counts,\n",
    "             labels={'x': 'Vehicle Type', 'y': 'Count of Crashes'})\n",
    "\n",
    "# Update the layout to rotate the x-axis labels\n",
    "fig9.update_layout(\n",
    "    xaxis_tickangle=-45,\n",
    "    plot_bgcolor = \"#31302F\", \n",
    "    paper_bgcolor = \"#31302F\",\n",
    "    font=dict(family=\"Open Sans\", color='#9467bd')\n",
    ")\n",
    "\n",
    "fig9.update_traces(marker_color = '#e377c2')\n",
    "\n",
    "# Show the plot\n",
    "fig9.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9148ff3",
   "metadata": {},
   "source": [
    "## Number of collisions for boroughs within each days of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3d6121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Day and Borough Data\n",
    "weekday_bor_df = df.select(F.col('BOROUGH').alias('borough'), F.col('day_of_week').alias('day'))\n",
    "\n",
    "# Group by 'borough' and 'day', then count the occurrences\n",
    "weekday_bor_df = weekday_bor_df.groupBy(\"borough\", \"day\").count()\n",
    "\n",
    "# Renaming the 'count' column to 'Crash_Count'\n",
    "weekday_bor_df_heatmap = weekday_bor_df.withColumnRenamed(\"count\", \"Crash_Count\")\n",
    "\n",
    "# Converting the PySpark DataFrame to a Pandas DataFrame\n",
    "weekday_bor_df_heatmap = weekday_bor_df_heatmap.toPandas()\n",
    "\n",
    "# Pivot the table to prepare for Heatmap data\n",
    "heatmap_data_pivot = weekday_bor_df_heatmap.pivot(index='day', columns='borough', values='Crash_Count').fillna(0)\n",
    "\n",
    "# Create the heatmap using Plotly\n",
    "fig10 = go.Figure(data=go.Heatmap(\n",
    "    z=heatmap_data_pivot.values,\n",
    "    x=heatmap_data_pivot.columns,\n",
    "    y=heatmap_data_pivot.index,\n",
    "    colorscale='matter'\n",
    "))\n",
    "\n",
    "# Add annotations - one for each cell in the heatmap\n",
    "annotations = []\n",
    "for n, row in enumerate(heatmap_data_pivot.values):\n",
    "    for m, val in enumerate(row):\n",
    "        annotations.append(\n",
    "            go.layout.Annotation(\n",
    "                text=str(val),\n",
    "                x=heatmap_data_pivot.columns[m],\n",
    "                y=heatmap_data_pivot.index[n],\n",
    "                xref='x1', yref='y1',\n",
    "                showarrow=False,\n",
    "                font=dict(color=\"black\")\n",
    "            )\n",
    "        )\n",
    "\n",
    "# Update the layout to include the annotations\n",
    "fig10.update_layout(\n",
    "    xaxis_title='Boroughs',\n",
    "    yaxis_title='Week Day of Crash',\n",
    "    annotations=annotations,\n",
    "    yaxis=dict(\n",
    "        tickmode='array',\n",
    "        tickvals=list(heatmap_data_pivot.index),\n",
    "        ticktext=['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "    ),\n",
    "    yaxis_tickangle=0,\n",
    "    plot_bgcolor = \"#000000\", \n",
    "    paper_bgcolor = \"#000000\",\n",
    "    font=dict(family=\"Open Sans\", color='#9467bd')\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig10.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8409a42f",
   "metadata": {},
   "source": [
    "## Number of collisions for boroughs within each hour of the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23729f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Crash Hour and Borough Data\n",
    "bor_hour_df = df.select('BOROUGH', 'hour_of_day')\n",
    "\n",
    "# Grouping by Borough and Hour, then counting\n",
    "bor_hour_df_heatmap = bor_hour_df.groupBy(\"BOROUGH\", \"hour_of_day\").count()\n",
    "\n",
    "# Renaming the 'count' column to 'Crash_Count'\n",
    "bor_hour_df_heatmap = bor_hour_df_heatmap.withColumnRenamed(\"count\", \"Crash_Count\")\n",
    "\n",
    "# Pivoting the table for Heatmap data\n",
    "heatmap_data_pivot = bor_hour_df_heatmap.groupBy(\"hour_of_day\").pivot(\"BOROUGH\").sum(\"Crash_Count\").sort(F.col('hour_of_day'))\n",
    "\n",
    "# Replacing null values with 0\n",
    "heatmap_data_pivot = heatmap_data_pivot.na.fill(0)\n",
    "\n",
    "heatmap_data_pd = heatmap_data_pivot.toPandas()\n",
    "heatmap_data_pd = heatmap_data_pd.drop('hour_of_day', axis=1)\n",
    "\n",
    "# Create a heatmap using seaborn\n",
    "fig11 = px.imshow(heatmap_data_pd, \n",
    "                labels=dict(x=\"Borough\", y=\"Hour of the Day\", color=\"Collisions\"),\n",
    "                x=heatmap_data_pd.columns,\n",
    "                y=heatmap_data_pd.index,\n",
    "                color_continuous_scale='curl',\n",
    "                text_auto=True)\n",
    "\n",
    "fig11.update_xaxes(side=\"bottom\")\n",
    "fig11.update_layout(    \n",
    "    plot_bgcolor = \"#000000\", \n",
    "    paper_bgcolor = \"#000000\",\n",
    "    font=dict(family=\"Open Sans\", color='#9467bd')\n",
    ")\n",
    "\n",
    "fig11.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2cab5c",
   "metadata": {},
   "source": [
    "## Deaths occurred within each borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db4b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_borough_data = df.select('NUMBER OF PERSONS KILLED', 'NUMBER OF PEDESTRIANS KILLED', \n",
    "          'NUMBER OF CYCLIST KILLED', 'NUMBER OF MOTORIST KILLED', \n",
    "          'BOROUGH').groupby('BOROUGH').\\\n",
    "          agg(F.sum('NUMBER OF PEDESTRIANS KILLED').alias('NUMBER OF PEDESTRIANS KILLED'),\\\n",
    "              F.sum('NUMBER OF CYCLIST KILLED').alias('NUMBER OF CYCLIST KILLED'),\\\n",
    "              F.sum('NUMBER OF MOTORIST KILLED').alias('NUMBER OF MOTORIST KILLED'),\\\n",
    "             ).collect()\n",
    "\n",
    "boroughs = [ind['BOROUGH'] for ind in deaths_borough_data]\n",
    "X = [ind['NUMBER OF PEDESTRIANS KILLED'] for ind in deaths_borough_data]\n",
    "Y = [ind['NUMBER OF CYCLIST KILLED'] for ind in deaths_borough_data]\n",
    "Z = [ind['NUMBER OF MOTORIST KILLED'] for ind in deaths_borough_data]\n",
    "\n",
    "death_bor_df = pd.DataFrame(np.c_[X,Z, Y], index=boroughs)\n",
    "\n",
    "# Plotting\n",
    "fig12 = go.Figure()\n",
    "fig12.add_trace(go.Bar(x=death_bor_df.index, y=death_bor_df[0], name='Pedestrians'))\n",
    "fig12.add_trace(go.Bar(x=death_bor_df.index, y=death_bor_df[1], name='Motorists'))\n",
    "fig12.add_trace(go.Bar(x=death_bor_df.index, y=death_bor_df[2], name='Cyclists'))\n",
    "\n",
    "# Update the layout\n",
    "fig12.update_layout(\n",
    "    barmode='group',\n",
    "    xaxis_title='Boroughs',\n",
    "    yaxis_title='Death Counts',\n",
    "    plot_bgcolor = \"#31302F\", \n",
    "    paper_bgcolor = \"#31302F\",\n",
    "    font=dict(family=\"Open Sans\", color='#9467bd'),\n",
    "    legend=dict(title='Categories', itemclick='toggle')\n",
    ")\n",
    "# Show the plot\n",
    "fig12.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644d9006",
   "metadata": {},
   "source": [
    "## Which vehicle type killed the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05124ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_code_combined = df.select('VEHICLE TYPE CODE 1' , 'NUMBER OF PERSONS KILLED')\\\n",
    "                          .groupby('VEHICLE TYPE CODE 1').agg(F.sum('NUMBER OF PERSONS KILLED')\\\n",
    "                                                              .alias('NUMBER OF PERSONS KILLED'))\\\n",
    "                                                              .sort(F.col('NUMBER OF PERSONS KILLED'), ascending=False)\n",
    "\n",
    "vehicle_code_data = vehicle_code_combined.collect()\n",
    "vehicle_code_data = [[ind['VEHICLE TYPE CODE 1'], ind['NUMBER OF PERSONS KILLED']] for ind in vehicle_code_data]\n",
    "\n",
    "# Removing empty values\n",
    "empty_value_list = [None, 'None', 'UNKNOWN', 'OTHER']\n",
    "vehicle_code_data_filtered = [sublist for sublist in vehicle_code_data if sublist[0] not in empty_value_list]\n",
    "\n",
    "# Merging values that are the same but written differently\n",
    "# To later delete duplciates\n",
    "\n",
    "\n",
    "# Function to merge values\n",
    "def vehicle_code_merge(vehicle, data):\n",
    "    vehicle_ele = [vehicle, 0]\n",
    "    # To store indices of duplicates\n",
    "    del_inds = []\n",
    "    for ind, sub_l in enumerate(data):\n",
    "        if re.search(vehicle, sub_l[0], re.IGNORECASE):\n",
    "            vehicle_ele[1] += sub_l[1]\n",
    "            del_inds.append(ind)\n",
    "    \n",
    "    data.append(vehicle_ele)\n",
    "    data = [i for j, i in enumerate(data) if j not in set(del_inds)]\n",
    "    \n",
    "    return data\n",
    "\n",
    "vehicle_code_data_filtered = vehicle_code_merge('Station Wagon', vehicle_code_data_filtered)\n",
    "vehicle_code_data_filtered = vehicle_code_merge('Sedan', vehicle_code_data_filtered)\n",
    "vehicle_code_data_filtered = vehicle_code_merge('Taxi', vehicle_code_data_filtered)\n",
    "vehicle_code_data_filtered = vehicle_code_merge('Bus', vehicle_code_data_filtered)\n",
    "vehicle_code_data_filtered = vehicle_code_merge('Truck', vehicle_code_data_filtered)\n",
    "vehicle_code_data_filtered = vehicle_code_merge('Van', vehicle_code_data_filtered)\n",
    "\n",
    "vehicle_code_data_filtered = sorted(vehicle_code_data_filtered, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Prepare the data for plotting\n",
    "top_vehicle_types = [str(i[0]) for i in vehicle_code_data_filtered[:5]]\n",
    "counts = [i[1] for i in vehicle_code_data_filtered[:5]]\n",
    "\n",
    "# Create the bar chart\n",
    "fig13 = px.bar(\n",
    "    x=top_vehicle_types,\n",
    "    y=counts,\n",
    "    labels={'x': 'Vehicle Type', 'y': 'Count of Crashes'}\n",
    ")\n",
    "\n",
    "# Update the layout for a better look\n",
    "fig13.update_layout(\n",
    "    xaxis_title='Vehicle Type',\n",
    "    yaxis_title='Count of Crashes',\n",
    "    xaxis_tickangle=-45,  # Rotate the x-axis labels\n",
    "    plot_bgcolor = \"#31302F\", \n",
    "    paper_bgcolor = \"#31302F\",\n",
    "    font=dict(family=\"Open Sans\", color='#9467bd')\n",
    ")\n",
    "\n",
    "fig13.update_traces(marker_color = '#e377c2')\n",
    "\n",
    "# Show the figure\n",
    "fig13.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a983e5c",
   "metadata": {},
   "source": [
    "## Top contribution factors for accidents borough wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410f14b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "contr_fact_bor_df = df.filter(F.col('CONTRIBUTING FACTOR VEHICLE 1') != \"Unspecified\")\\\n",
    "                      .select('BOROUGH', 'CONTRIBUTING FACTOR VEHICLE 1')\\\n",
    "                      .groupby('BOROUGH', 'CONTRIBUTING FACTOR VEHICLE 1')\\\n",
    "                      .count()\\\n",
    "                      .collect()\n",
    "\n",
    "contr_fact_bor_df = pd.DataFrame({'borough': [i['BOROUGH'] for i in contr_fact_bor_df],\n",
    "                                  'factor': [i['CONTRIBUTING FACTOR VEHICLE 1'] for i in contr_fact_bor_df],\n",
    "                                  'count': [i['count'] for i in contr_fact_bor_df]}).sort_values('count', ascending=False)[:100]\n",
    "\n",
    "# Pivot the table to prepare for Heatmap data\n",
    "heatmap_data_pivot = contr_fact_bor_df.pivot(index='factor', columns='borough', values='count').fillna(0)\n",
    "\n",
    "# Create a heatmap using Plotly\n",
    "fig14 = go.Figure(data=go.Heatmap(\n",
    "    z=heatmap_data_pivot.values,\n",
    "    x=heatmap_data_pivot.columns,\n",
    "    y=heatmap_data_pivot.index,\n",
    "    colorscale='matter'\n",
    "))\n",
    "\n",
    "# Add text annotations with the values\n",
    "for y in range(heatmap_data_pivot.shape[0]):\n",
    "    for x in range(heatmap_data_pivot.shape[1]):\n",
    "        fig14.add_annotation(\n",
    "            x=heatmap_data_pivot.columns[x],\n",
    "            y=heatmap_data_pivot.index[y],\n",
    "            text=str(heatmap_data_pivot.iloc[y, x]),\n",
    "            showarrow=False,\n",
    "            font=dict(color='black')\n",
    "        )\n",
    "\n",
    "# Update the layout to set the axis titles and the chart title\n",
    "fig14.update_layout(\n",
    "    xaxis_title='Boroughs',\n",
    "    yaxis_title='Contributing Factors',\n",
    "    yaxis=dict(tickmode='array', tickvals=list(heatmap_data_pivot.index)),\n",
    "    xaxis=dict(side='bottom'),\n",
    "    plot_bgcolor = \"#31302F\", \n",
    "    paper_bgcolor = \"#31302F\",\n",
    "    font=dict(family=\"Open Sans\", color='#9467bd')\n",
    ")\n",
    "    \n",
    "# Show the figure\n",
    "fig14.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1894d083",
   "metadata": {},
   "source": [
    "# Geospatial Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e8e420",
   "metadata": {},
   "source": [
    "## Heatmap of Crash Locations over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521327d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year from Date\n",
    "df = df.withColumn('year', F.year('CRASH DATE'))\n",
    "\n",
    "# Extract month from 'CRASH_DATE'\n",
    "df = df.withColumn('month_year', F.concat_ws('/', df['Month'], df['year']))\n",
    "\n",
    "# Group by month and collect latitudes and longitudes\n",
    "df_grouped = df.groupBy('month_year').agg(\n",
    "    F.collect_list('LATITUDE').alias('latitudes'),\n",
    "    F.collect_list('LONGITUDE').alias('longitudes'),\n",
    "    F.collect_list('CONTRIBUTING FACTOR VEHICLE 1').alias('CONTRIBUTING FACTOR VEHICLE 1'),\n",
    "    F.collect_list('VEHICLE TYPE CODE 1').alias('VEHICLE TYPE CODE 1')\n",
    ")\n",
    "\n",
    "# To sort the dates\n",
    "def sortDateSeries(datesSeries):\n",
    "    def sortDate(dates):\n",
    "        split_up = dates.split('/')\n",
    "        return int(split_up[1]), int(split_up[0])\n",
    "    return datesSeries.apply(lambda x: sortDate(x))\n",
    "\n",
    "# Convert to Pandas DataFrame for visualization\n",
    "df_pandas = df_grouped.toPandas().sort_values('month_year', key=sortDateSeries)\n",
    "\n",
    "\n",
    "# # Prepare data for the heatmap\n",
    "hour_list = [[list(coordinate) for coordinate in zip(row['latitudes'], row['longitudes'])] for index, row in df_pandas.iterrows()]\n",
    "\n",
    "\n",
    "# Ensure index covers all months\n",
    "index = df_pandas['month_year'].unique().tolist()\n",
    "\n",
    "df_map = folium.Map(location=[40.7128, -74.0060], zoom_start=12)\n",
    "HeatMapWithTime(hour_list, index=index, auto_play=True, radius=8).add_to(df_map)\n",
    "df_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08129ae2",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9564b911",
   "metadata": {},
   "source": [
    "## Building an imputation model to predict Borough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6742208",
   "metadata": {},
   "source": [
    "Idea is to plug in missing Borough name in the data with some level of accuracy and not through pure descriptive statitistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93244697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create separate df for model preparation\n",
    "model_df = df_orig.alias('model_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98859941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate day, month, and year into three different features\n",
    "# Day of month\n",
    "model_df = model_df.withColumn('day', F.to_timestamp(F.regexp_replace('CRASH DATE', '/', '-'), \"MM-dd-yyyy\"))\\\n",
    "        .withColumn('day', F.day('day'))\n",
    "\n",
    "# Month\n",
    "model_df = model_df.withColumn('month', F.to_timestamp(F.regexp_replace('CRASH DATE', '/', '-'), \"MM-dd-yyyy\"))\\\n",
    "        .withColumn('month', F.month('month'))\n",
    "\n",
    "# Year\n",
    "model_df = model_df.withColumn('year', F.to_timestamp(F.regexp_replace('CRASH DATE', '/', '-'), \"MM-dd-yyyy\"))\\\n",
    "        .withColumn('year', F.year('year'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30545986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crash Time can be converted into a categorical variable with\n",
    "# 6AM - 12 PM : Morning\n",
    "# 12 PM - 5 PM : Afternoon\n",
    "# 5 PM - 10 PM : Evening\n",
    "# 10 PM - 6 AM : Night\n",
    "\n",
    "# Convert 'time' to timestamp\n",
    "model_df = model_df.withColumn('CRASH TIME', F.col('CRASH TIME').cast('timestamp'))\n",
    "\n",
    "# Define conditions for time categorization\n",
    "conditions = [\n",
    "    (F.hour('CRASH TIME') >= 6) & (F.hour('CRASH TIME') < 12),  # Morning\n",
    "    (F.hour('CRASH TIME') >= 12) & (F.hour('CRASH TIME') < 17),  # Afternoon\n",
    "    (F.hour('CRASH TIME') >= 17) & (F.hour('CRASH TIME') < 22)   # Evening\n",
    "]\n",
    "\n",
    "# Corresponding categories for each condition\n",
    "categories = ['Morning', 'Afternoon', 'Evening']\n",
    "\n",
    "# Use the 'when' function to apply conditions and create a new column 'time_category'\n",
    "model_df = model_df.withColumn('time_category', \n",
    "    F.when(conditions[0], categories[0])\n",
    "    .otherwise(F.when(conditions[1], categories[1])\n",
    "    .otherwise(F.when(conditions[2], categories[2])\n",
    "    .otherwise('Night'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e0f161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vehicle Type 1\n",
    "\n",
    "# Vehicle code variations\n",
    "common_vehicle_list_pattern = ['Station Wagon', 'Sedan', 'Taxi', 'Bus', 'Van',\n",
    "                       'Ambu', 'Motor', 'Bike', 'scoot', 'Fire']\n",
    "\n",
    "# Vehicle code replacements\n",
    "common_vehicle_list_category = ['Station Wagon', 'Sedan', 'Taxi', 'Bus', 'Van',\n",
    "                       'Ambulance', 'Motorcycle', 'Bike', 'Scooter', 'Fire Truck']\n",
    "\n",
    "# Variations of Truck\n",
    "truck_wrong = ['Dump', 'Garbage or Refuse', 'Concrete Mixer', 'LARGE COM VEH(6 OR MORE TIRES)', 'Flat Bed',\n",
    "               'Tanker', 'TOW T', 'BOX T', 'TRACT', 'DUMP', 'FDNY', 'Flat Rack']\n",
    "\n",
    "# Variations of Delivery\n",
    "delivery_wrong = ['LIVERY VEHICLE', 'Carry All', 'USPS', 'DELIV', 'COM', 'DELV']\n",
    "\n",
    "# Replace variations with proper names\n",
    "for ind in range(len(common_vehicle_list_pattern)):\n",
    "    model_df = model_df.withColumn(\n",
    "                'VEHICLE TYPE CODE 1',\n",
    "                F.when(F.col('VEHICLE TYPE CODE 1').ilike(f\"%{common_vehicle_list_pattern[ind]}%\"), common_vehicle_list_category[ind])\n",
    "                .otherwise(F.col('VEHICLE TYPE CODE 1')))\n",
    "\n",
    "# Replace variations of truck and delivery\n",
    "model_df = model_df.withColumn(\n",
    "    'VEHICLE TYPE CODE 1',\n",
    "    F.when(\n",
    "        F.col(\"VEHICLE TYPE CODE 1\").isin(truck_wrong),\n",
    "        \"Truck\"\n",
    "    ).when(\n",
    "        F.col(\"VEHICLE TYPE CODE 1\").isin(delivery_wrong),\n",
    "        \"Delivery\"\n",
    "    ).otherwise(F.col(\"VEHICLE TYPE CODE 1\"))\n",
    ")\n",
    "\n",
    "\n",
    "# If count of a specific vehicle code is less than 50, then replace it with \"Other\"\n",
    "other_list = [i['VEHICLE TYPE CODE 1'] for i in model_df.groupby('VEHICLE TYPE CODE 1') \\\n",
    "                                           .count() \\\n",
    "                                           .filter(F.col('count') < 50).collect()]\n",
    "\n",
    "model_df = model_df.withColumn(\n",
    "    'VEHICLE TYPE CODE 1',\n",
    "    F.when(\n",
    "        F.col('VEHICLE TYPE CODE 1').isin(other_list),\n",
    "        \"Other\"\n",
    "    ).otherwise(F.col('VEHICLE TYPE CODE 1')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d32377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature list to identify which features the model should train on\n",
    "features_to_keep = ['day','month','year','time_category',\n",
    "                    'VEHICLE TYPE CODE 1', 'CONTRIBUTING FACTOR VEHICLE 1', 'NUMBER OF PERSONS KILLED',\n",
    "                    'NUMBER OF PERSONS INJURED', 'LONGITUDE', 'LATITUDE', 'BOROUGH']\n",
    "\n",
    "# Extracting selected features out of the dataframe\n",
    "train_data = model_df.select(features_to_keep)\n",
    "\n",
    "# Dropping any NaNs\n",
    "train_data = train_data.na.drop(how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44123b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PySpark doesn't take categorical variables as Target variables. So, encoding the Boroughs with a monotonic series\n",
    "borough_mapping = {'QUEENS':1, 'BROOKLYN':2, 'BRONX':3, 'MANHATTAN':4, 'STATEN ISLAND':5}\n",
    "\n",
    "# Creating a map for the borough to transform values\n",
    "mapping_expr = F.create_map([F.lit(x) for x in chain(*borough_mapping.items())])\n",
    "\n",
    "# Implementing the mapping on the dataset\n",
    "train_data = train_data.withColumn('target', mapping_expr[train_data['BOROUGH']])\n",
    "\n",
    "# This is lowest count of datapoints in the dataset. So, to keep a balanced dataset, taking 56000 from each class\n",
    "lowest_class_count = 56000\n",
    "\n",
    "# Identifying the fraction of data required from each class\n",
    "fractions = train_data.groupBy('target').count().withColumn(\"required_n\", lowest_class_count/F.col(\"count\"))\\\n",
    "                .drop(\"count\").rdd.collectAsMap()\n",
    "\n",
    "# Extracting the fraction of data from each class\n",
    "train_data = train_data.stat.sampleBy('target', fractions, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc4e36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Injured Persons row to Integer\n",
    "train_data = train_data.withColumn('NUMBER OF PERSONS INJURED', F.col('NUMBER OF PERSONS INJURED').cast(IntegerType()))\n",
    "\n",
    "# StringIndexer for encoding string features\n",
    "train_string_features = ['time_category', 'VEHICLE TYPE CODE 1', 'CONTRIBUTING FACTOR VEHICLE 1']\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=col+\"_index\", handleInvalid=\"skip\") for col in train_string_features]\n",
    "\n",
    "# Assemble all features into a single vector\n",
    "train_numeric_features = ['day','month','year', 'NUMBER OF PERSONS INJURED', 'LONGITUDE', 'LATITUDE']\n",
    "assembler_inputs = [col + \"_index\" for col in train_string_features] + train_numeric_features\n",
    "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n",
    "\n",
    "# StringIndexer for encoding the target variable\n",
    "label_indexer = StringIndexer(inputCol='target', outputCol=\"label\", handleInvalid=\"skip\")\n",
    "\n",
    "# Create a Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=10, maxDepth=3, maxBins=62)\n",
    "\n",
    "# Create a pipeline to chain indexers, assembler, and the classifier\n",
    "pipeline = Pipeline(stages=indexers + [assembler, label_indexer, rf_classifier])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "(training_data, testing_data) = train_data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Train the Random Forest model\n",
    "model = pipeline.fit(training_data)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.transform(testing_data)\n",
    "\n",
    "# Storing the essential columns for performance metric generation\n",
    "preds_df = predictions.select('target', 'prediction', 'probability').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24e0a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating true labels and predictions for performance metric calculations\n",
    "true_labels = [i['target'] for i in preds_df]\n",
    "preds = [i['prediction'] for i in preds_df]\n",
    "\n",
    "print(\"Overall Accuracy:\", accuracy_score(true_labels, preds))\n",
    "print(\"Individual Recall scores:\",recall_score(true_labels, preds, average=None))\n",
    "print(\"Individual Precision scores:\",precision_score(true_labels, preds, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7282309e",
   "metadata": {},
   "source": [
    "# Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c84f326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a seperate dataframe for dashboard data processing\n",
    "dashboard_df = df_orig.alias('dashboard_df')\n",
    "\n",
    "# Ensure the 'CRASH DATE' column is in datetime format\n",
    "dashboard_df = dashboard_df.withColumn('CRASH DATE', F.to_timestamp(F.regexp_replace('CRASH DATE', '/', '-'), \"MM-dd-yyyy\"))\n",
    "\n",
    "# Extract the month from the date\n",
    "dashboard_df = dashboard_df.withColumn('Month', F.month('CRASH DATE'))\n",
    "\n",
    "# Extract day of the week (1=Sunday, 7=Saturday) and hour of the day\n",
    "dashboard_df = dashboard_df.withColumn('day_of_week', F.dayofweek(F.col('CRASH DATE')))\n",
    "dashboard_df = dashboard_df.withColumn('hour_of_day', F.hour(F.col('CRASH TIME')))\n",
    "\n",
    "# Extract year from Date\n",
    "dashboard_df = dashboard_df.withColumn('year', F.year('CRASH DATE'))\n",
    "\n",
    "# Extract month from 'CRASH_DATE'\n",
    "dashboard_df = dashboard_df.withColumn('month_year', F.concat_ws('/', dashboard_df['Month'], dashboard_df['year']))\n",
    "\n",
    "# Extracting data into Pandas Dataframe\n",
    "dashboard_df_pd =  dashboard_df.toPandas()\n",
    "\n",
    "# Dropping NaNs from the following features, as we are using them in the maps\n",
    "dashboard_df_pd.dropna(subset=['LATITUDE', 'LONGITUDE', \"ZIP CODE\", \n",
    "                               \"CONTRIBUTING FACTOR VEHICLE 1\", \"VEHICLE TYPE CODE 1\" ], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e9f219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe according to month and year\n",
    "dashboard_df_pd = dashboard_df_pd.sort_values('month_year', key=sortDateSeries)\n",
    "\n",
    "# Get all the month and year dates\n",
    "month_year_list = dashboard_df_pd['month_year'].unique().tolist()\n",
    "\n",
    "# Taking the top 25 contributing factors since there are some sparse ones\n",
    "contributing_factors_list = dashboard_df_pd['CONTRIBUTING FACTOR VEHICLE 1'].value_counts().index.tolist()[:25]\n",
    "\n",
    "# Taking the top 25 vehicle codes since there are some sparse ones\n",
    "vehicle_code_list = dashboard_df_pd['VEHICLE TYPE CODE 1'].value_counts().index.tolist()[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5626f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dash App\n",
    "app = Dash(__name__)\n",
    "\n",
    "\n",
    "app.css.config.serve_locally = True\n",
    "app.css.append_css({\"external_url\": r\"C:\\Users\\91830\\Documents\\Notebooks\\Big_data_project\\assets\\main.css\"})\n",
    "app.server.static_folder = \"assets\"\n",
    "\n",
    "app.layout = html.Div(children=[\n",
    "    \n",
    "    html.H1(\"MOTOR CRASH ANALYSIS - A DEEP DIVE INTO ITS FACTORS AND CAUSES\", \n",
    "            style={'font-family':'Open Sans Semi Bold', 'font-weight':'bold', 'letter-spacing': '4px',\n",
    "                  'font-size':'30px'}),\n",
    "    \n",
    "    html.Div([\n",
    "    html.H2('Month wise plot of number of accidents'),\n",
    "    dcc.Graph(id=\"graph1\", figure=fig1.update_layout(height=600))], className='div-for-charts'),\n",
    "    \n",
    "    html.Div([\n",
    "    html.H2('How frequent the accident happened by day of week and hour of day?'),\n",
    "    dcc.Graph(id=\"graph2\", figure=fig2.update_layout(height=600))], className='div-for-charts'),\n",
    "    \n",
    "    html.Div([\n",
    "    html.H2('Cumulative Daily Total of Traffic Fatalities'),\n",
    "    dcc.Graph(id=\"graph3\", figure=fig3.update_layout(height=600))], className='div-for-charts'),\n",
    "    \n",
    "    html.Div([\n",
    "    html.H2('Number of total people killed in crashes'),\n",
    "    dcc.Graph(id=\"graph4\", figure=fig4.update_layout(height=600))], className='div-for-charts'),\n",
    "    \n",
    "    html.Div([\n",
    "    html.H2('Cumulative Daily Total of Traffic Injuries'),\n",
    "    dcc.Graph(id=\"graph5\", figure=fig5.update_layout(height=600))], className='div-for-charts'),\n",
    "\n",
    "    html.Div([\n",
    "    html.H2('Number of total people injured in crashes'),\n",
    "    dcc.Graph(id=\"graph6\", figure=fig6.update_layout(height=600))], className='div-for-charts'),\n",
    "\n",
    "    html.Div([\n",
    "    html.H2('Top 10 Streets with the Most Reported Accidents'),\n",
    "    dcc.Graph(id=\"graph7\", figure=fig7.update_layout(height=600))], className='div-for-charts'),\n",
    "    \n",
    "    html.Div([\n",
    "    html.H2('Top 10 contribution factors for accidents'),\n",
    "    dcc.Graph(id=\"graph8\", figure=fig8.update_layout(height=600))], className='div-for-charts'),\n",
    "    \n",
    "    html.Div([\n",
    "    html.H2('Which vehicle type was involved in most crashes'),\n",
    "    dcc.Graph(id=\"graph9\", figure=fig9.update_layout(height=600))], className='div-for-charts'),\n",
    "    \n",
    "    html.Div([\n",
    "    html.H2('Number of collisions for boroughs within each days of week'),\n",
    "    dcc.Graph(id=\"graph10\", figure=fig10.update_layout(height=600))], className='div-for-charts'),\n",
    "    \n",
    "    html.Div([\n",
    "    html.H2('Number of collisions for boroughs within each hour of the day'),\n",
    "    dcc.Graph(id=\"graph11\", figure=fig11.update_layout(height=600))], className='div-for-charts'),\n",
    "    \n",
    "    html.Div([\n",
    "    html.H2('Deaths occurred within each borough'),\n",
    "    dcc.Graph(id=\"graph12\", figure=fig12.update_layout(height=600))], className='div-for-charts'),\n",
    "    \n",
    "    html.Div([\n",
    "    html.H2('Which vehicle type killed the most'),\n",
    "    dcc.Graph(id=\"graph13\", figure=fig13.update_layout(height=600))], className='div-for-charts'),\n",
    "\n",
    "    html.Div([\n",
    "    html.H2('Top contribution factors for accidents borough wise'),\n",
    "    dcc.Graph(id=\"graph14\", figure=fig14.update_layout(height=600))], className='div-for-charts'),\n",
    "\n",
    "    html.Div([\n",
    "        html.H2('Map view of Motor Crashes over time'),\n",
    "        html.Iframe(id='map1', srcDoc = open(\"Month_year_visualization.html\", 'r').read(), \n",
    "                    width='1024', height='768', className='div-center')],\n",
    "    ),\n",
    "\n",
    "    html.Div(children=[\n",
    "        html.H2(children='Interactive Selection Map'),\n",
    "\n",
    "        # Dropdown for selecting Contributing Factor\n",
    "        dcc.Dropdown(\n",
    "            id='contributing-factor-dropdown',\n",
    "            options=[\n",
    "                {'label': factor, 'value': factor} for factor in contributing_factors_list\n",
    "            ],\n",
    "            value=contributing_factors_list[0],\n",
    "            style={'width': '100%'}\n",
    "        ),\n",
    "\n",
    "        # Dropdown for selecting Contributing Factor\n",
    "        dcc.Dropdown(\n",
    "            id='vehicle-code-dropdown',\n",
    "            options=[\n",
    "                {'label': factor, 'value': factor} for factor in vehicle_code_list\n",
    "            ],\n",
    "            value=vehicle_code_list[0],\n",
    "            style={'width': '100%'}\n",
    "        ),\n",
    "\n",
    "        # Dropdown for selecting Contributing Factor\n",
    "        dcc.Dropdown(\n",
    "            id='month-year-dropdown',\n",
    "            options=[\n",
    "                {'label': factor, 'value': factor} for factor in month_year_list\n",
    "            ],\n",
    "            value=month_year_list[0],\n",
    "            style={'width': '100%'}\n",
    "        ),\n",
    "\n",
    "        # Map to display the points\n",
    "        dcc.Graph(\n",
    "            id='contributing-factor-map'\n",
    "        )\n",
    "        \n",
    "    ], className='div-for-charts')\n",
    "\n",
    "])\n",
    "\n",
    "# Define callback to update the map based on the selected Contributing Factor\n",
    "@app.callback(\n",
    "    Output('contributing-factor-map', 'figure'),\n",
    "    [Input('contributing-factor-dropdown', 'value'), Input('vehicle-code-dropdown', 'value'),\n",
    "    Input('month-year-dropdown', 'value')]\n",
    ")\n",
    "def update_map(selected_factor, selected_vehicle, selected_date):\n",
    "    # Filter data based on the selected Contributing Factor\n",
    "    filtered_data = dashboard_df_pd[\n",
    "        (dashboard_df_pd['month_year'] == selected_date) & \\\n",
    "        (dashboard_df_pd['CONTRIBUTING FACTOR VEHICLE 1'] == selected_factor) & \\\n",
    "        (dashboard_df_pd['VEHICLE TYPE CODE 1'] == selected_vehicle) \\\n",
    "    ]\n",
    "    \n",
    "    if filtered_data.shape[0] != 0:\n",
    "        # Create a map with markers\n",
    "        fig = px.scatter_mapbox(\n",
    "            filtered_data,\n",
    "            lat='LATITUDE',\n",
    "            lon='LONGITUDE',\n",
    "            size_max=15,\n",
    "            zoom=10\n",
    "        )\n",
    "    else:\n",
    "        fig = px.scatter_mapbox(\n",
    "            dashboard_df_pd.iloc[:2],\n",
    "            lat='LATITUDE',\n",
    "            lon='LONGITUDE',\n",
    "            size_max=15,\n",
    "            zoom=10,\n",
    "            opacity=0\n",
    "        ) \n",
    "\n",
    "    # Customize the map layout\n",
    "    fig.update_layout(\n",
    "        mapbox_style='carto-darkmatter',\n",
    "        mapbox_zoom=10,\n",
    "        mapbox_center={'lat': dashboard_df_pd['LATITUDE'].mean(), 'lon': dashboard_df_pd['LONGITUDE'].mean()},\n",
    "        plot_bgcolor = \"#31302F\", \n",
    "        paper_bgcolor = \"#31302F\",\n",
    "        font=dict(family=\"Open Sans\", color='#9467bd')\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "app.run_server(debug=True,  jupyter_mode='tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1effa92c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
